#bash: pip install ultralytics opencv-python

import cv2
from ultralytics import YOLO

# --- Configuration ---
# 1. Load the pre-trained YOLOv8 model (using 'n' for fast, 's' for balanced speed/accuracy)
model = YOLO('yolov8n.pt') 

# COCO dataset class ID for 'person' is 0. 
# We only want to detect pedestrians/persons.
PERSON_CLASS_ID = 0 

# Minimum confidence score required to display a detection
CONFIDENCE_THRESHOLD = 0.5

# --- Video Input ---
# Use 0 for a live webcam stream, or 'path/to/your/video.mp4' for a video file
video_source = 0 
cap = cv2.VideoCapture(video_source) 

# --- Detection Loop ---
while cap.isOpened():
    # Read a frame from the video stream
    success, frame = cap.read()
    
    if not success:
        print("End of video stream or error reading frame.")
        break
    
    # Run YOLOv8 inference on the frame
    # results is a list of objects, one for each image passed (here, just one frame)
    results = model(frame, verbose=False) 

    # Process the first (and only) result object
    if results:
        r = results[0]
        
        # Get the bounding boxes, confidence scores, and class IDs
        # .data converts the results to a PyTorch tensor, .cpu().numpy() moves it to CPU for OpenCV
        boxes = r.boxes.xyxy.cpu().numpy().astype(int) 
        confs = r.boxes.conf.cpu().numpy()              
        classes = r.boxes.cls.cpu().numpy()             

        # Iterate through all detected objects
        for box, conf, cls in zip(boxes, confs, classes):
            # Filter: Check if the object is a 'person' (class ID 0) and meets the threshold
            if cls == PERSON_CLASS_ID and conf >= CONFIDENCE_THRESHOLD:
                x1, y1, x2, y2 = box
                
                # --- Draw Visualization ---
                # Draw the bounding box (Green BGR)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # Create the label text
                label = f'Pedestrian: {conf:.2f}'
                
                # Draw the label and confidence score above the box
                cv2.putText(frame, label, (x1, y1 - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the resulting frame
    cv2.imshow("Enhanced Pedestrian Detection (YOLOv8)", frame)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- Cleanup ---
cap.release()
cv2.destroyAllWindows()